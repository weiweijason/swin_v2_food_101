# Swin Transformer V2 於 Food-101 資料集分類

這個專案使用 Swin Transformer V2 模型對 Food-101 食物圖像資料集進行分類訓練。

## 專案簡介

本專案使用最新的 Swin Transformer V2 模型架構，針對 Food-101 資料集（包含 101 類食物圖像）進行分類任務訓練。專案特色：

- 使用 Swin Transformer V2 模型進行深度學習
- 採用分散式訓練（DistributedDataParallel）提高訓練效率
- 應用混合精度訓練（AMP）加速訓練過程
- 整合進階資料增強技術如 RandAugment、Mixup 和 Cutmix
- 採用 Stochastic Depth 提高深層網路泛化能力
- 使用 Tensorboard 視覺化訓練過程和關鍵指標
- 完整的日誌記錄系統
- 自適應錯誤處理機制以提高訓練穩定性

## 最新更新 (2025年5月14日)

### 解決 CUDA 內存問題與 DataLoader 錯誤

針對在訓練過程中出現的 CUDA 記憶體不足問題和評估階段的 DataLoader 錯誤，我們實施了以下關鍵修改：

1. **修復 DataLoader 批次大小設定問題**
   - 移除嘗試在 DataLoader 初始化後修改其 `batch_size` 屬性的代碼
   - 確保測試數據加載器和訓練數據加載器使用相同的批次大小設定
   - 修正代碼結構中的語法錯誤，包括缺少的換行符和不當的註釋放置

2. **優化代碼組織與記憶體管理**
   - 確保 train_loader 和 test_loader 定義的適當分隔，避免語法錯誤
   - 提高代碼可讀性和維護性，便於未來的擴展和優化
   - 改進錯誤處理機制，提供更詳細的診斷信息

這些修改確保了訓練和評估過程的穩定性，有效解決了之前在評估階段遇到的錯誤問題。

### 應對過度正則化的模型調整 (2025年5月12日)

面對測試準確率(37.92%)與訓練準確率(31.33%)同時偏低的情況，我們實施了以下參數調整：

1. **優化窗口大小**
   - 將窗口大小從7增加到12，以捕捉更大範圍的特徵關係
   - 更好地適應食物圖像中的多尺度紋理和形狀特徵

2. **降低正則化強度**
   - 將dropout_path從0.3降低到0.2，減少隨機丟棄強度
   - 將權重衰減從0.02/0.05降低到0.01/0.03，允許模型更靈活地擬合訓練數據

3. **減輕數據增強強度**
   - 降低顏色變化範圍：(0.7,1.3) → (0.8,1.2)
   - 減少旋轉角度：(-20,20) → (-10,10)
   - 降低透視變換強度：0.2 → 0.1，概率：0.5 → 0.3
   - 降低隨機擦除概率：0.3 → 0.2

4. **調整混合策略**
   - Mixup強度從0.2降低到0.1
   - Cutmix強度從0.2降低到0.1
   - 應用概率從0.6降低到0.4
   - 標籤平滑從0.05減少到0.03

5. **重設學習率策略**
   - 主幹學習率提高10倍：5e-6 → 1e-5
   - 分類頭學習率提高10倍：5e-5 → 1e-4
   - 最小學習率提高10倍：1e-7 → 1e-6
   - 縮短預熱期：5個epoch → 2個epoch

6. **增加總訓練輪數**
   - 從50輪增加到80輪，給新參數足夠的學習時間

這些調整旨在解決模型過度正則化的問題，使模型在保持泛化能力的同時，能更有效地學習訓練數據的特徵。

### 進階學習率與優化器設置

為了更好地控制模型收斂過程，實施了以下優化：

- **分層學習率策略**：模型主幹網絡使用5e-6學習率，分類頭使用5e-5學習率
- **更優化的學習率調度**：使用CosineLRScheduler，5個epoch預熱期，從1e-7升至目標學習率
- **優化器參數調整**：AdamW優化器使用權重衰減0.02(主幹)和0.05(分類頭)，提高泛化能力
- **標籤平滑處理**：降低標籤平滑強度至0.05，避免模型過度自信

### 環境配置與訓練注意事項 (新增)

在最新的分散式訓練過程中，我們注意到以下重要事項：

1. **NCCL環境變數更新**
   - 舊版變數 `NCCL_BLOCKING_WAIT` 已棄用，應改用 `TORCH_NCCL_BLOCKING_WAIT`
   - 舊版變數 `NCCL_ASYNC_ERROR_HANDLING` 已棄用，應改用 `TORCH_NCCL_ASYNC_ERROR_HANDLING`
   - 我們已在代碼中更新這些設置以符合最新標準

2. **GPU P2P通信警告**
   - 訓練日誌顯示 P2P 通信在 GPU 之間被禁用，這可能會影響性能
   - 可通過設置 `NCCL_IGNORE_DISABLED_P2P=1` 來抑制相關警告，但不會解決根本問題
   - 在雲端環境中，GPU 間 P2P 通信可能受到限制，特別是在虛擬機或容器化環境中

3. **AMP GradScaler 更新**
   - 舊版的 `torch.cuda.amp.GradScaler()` 已棄用
   - 應使用 `torch.amp.GradScaler('cuda', ...)` 替代
   - 此變更將在未來版本中實施

4. **分散式初始化改進**
   - 添加了設備 ID 指定，避免因錯誤的 rank-GPU 映射導致的潛在死鎖
   - 使用 barrier 確保所有進程在每個 epoch 前後同步，提高穩定性

5. **PyTorch 序列化安全更新**
   - `torch.load()` 將在未來默認設置 `weights_only=True`
   - 建議顯式指定 `weights_only=True` 以增強安全性，特別是加載不受信任的模型時

這些配置更新反映了深度學習框架的最新最佳實踐，並有助於提高訓練的穩定性和安全性。

## 模型參數設置 (2025年5月8日更新)

| 參數 | 數值 | 說明 |
|------|------|------|
| 學習率 | 5e-6 (主幹) / 5e-5 (分類頭) | 採用分層學習率策略 |
| 預熱週期 | 5個epoch | 從非常小的學習率(1e-7)開始預熱 |
| 權重衰減 | 0.02 (主幹) / 0.05 (分類頭) | 根據不同層次調整正則化強度 |
| 數據增強 | 高級增強 + 漸進式調整 | 訓練進行時動態增加增強強度 |
| 測試增強 | TTA (Test Time Augmentation) | 結合原始、翻轉和縮放預測 |
| Mixup強度 | 0.2 (降低) | 避免過度混合類別信息 |
| Cutmix強度 | 0.2 (降低) | 減輕標籤干擾，提高鑑別能力 |
| dropout_path | 0.3 (增強) | 增強丟棄路徑概率，防止過擬合 |

### 模型評估與保存機制改進

- **測試時增強評估**：最後5個epoch採用TTA進行更精確評估
- **多層次檢查點**：除最佳模型外，每5個epoch保存階段性檢查點
- **帶時間戳的模型保存**：避免最佳模型被覆蓋，保留歷史最佳記錄
- **緊急檢查點機制**：訓練中斷時自動保存當前狀態，便於恢復

## 最新更新 (2025年5月6日)

### 針對過擬合問題的優化

在觀察到訓練過程中出現明顯的過擬合現象（Training accuracy: 85.19%, Testing accuracy: 58.04%）後，我們實施了以下優化措施：

1. **增強正則化**
   - 將權重衰減(Weight Decay)從0.05增加到0.1，顯著增強了模型的正則化強度
   - 這有助於減少模型對訓練數據的過度記憶，提高泛化能力

2. **增強數據增強策略**
   - 新增隨機旋轉(Random Rotation)：最大15度
   - 添加顏色抖動(Color Jitter)：調整亮度、對比度、飽和度和色調
   - 引入隨機平移(Random Affine)：最大平移範圍為10%
   - 添加隨機擦除(Random Erasing)：以0.2的概率隨機遮擋圖像區域
   - 這些增強技術強制模型學習更加泛化的特徵，而非記憶特定細節

## 模型參數設置 (2025年5月8日更新)

| 參數 | 數值 | 說明 |
|------|------|------|
| 學習率 | 5e-6 (主幹) / 5e-5 (分類頭) | 採用分層學習率策略 |
| 預熱週期 | 5個epoch | 從非常小的學習率(1e-7)開始預熱 |
| 權重衰減 | 0.02 (主幹) / 0.05 (分類頭) | 根據不同層次調整正則化強度 |
| 數據增強 | 高級增強 + 漸進式調整 | 訓練進行時動態增加增強強度 |
| 測試增強 | TTA (Test Time Augmentation) | 結合原始、翻轉和縮放預測 |
| Mixup強度 | 0.2 (降低) | 避免過度混合類別信息 |
| Cutmix強度 | 0.2 (降低) | 減輕標籤干擾，提高鑑別能力 |
| dropout_path | 0.3 (增強) | 增強丟棄路徑概率，防止過擬合 |

### 模型評估與保存機制改進

- **測試時增強評估**：最後5個epoch採用TTA進行更精確評估
- **多層次檢查點**：除最佳模型外，每5個epoch保存階段性檢查點
- **帶時間戳的模型保存**：避免最佳模型被覆蓋，保留歷史最佳記錄
- **緊急檢查點機制**：訓練中斷時自動保存當前狀態，便於恢復

## 最新更新 (2025年5月6日)

### 針對過擬合問題的優化

在觀察到訓練過程中出現明顯的過擬合現象（Training accuracy: 85.19%, Testing accuracy: 58.04%）後，我們實施了以下優化措施：

1. **增強正則化**
   - 將權重衰減(Weight Decay)從0.05增加到0.1，顯著增強了模型的正則化強度
   - 這有助於減少模型對訓練數據的過度記憶，提高泛化能力

2. **增強數據增強策略**
   - 新增隨機旋轉(Random Rotation)：最大15度
   - 添加顏色抖動(Color Jitter)：調整亮度、對比度、飽和度和色調
   - 引入隨機平移(Random Affine)：最大平移範圍為10%
   - 添加隨機擦除(Random Erasing)：以0.2的概率隨機遮擋圖像區域
   - 這些增強技術強制模型學習更加泛化的特徵，而非記憶特定細節

## 模型參數設置 (2025年5月6日更新)

優化後的參數配置：

| 參數 | 數值 | 說明 |
|------|------|------|
| 權重衰減 | 0.1 (微調) | 從0.05增加到0.1以增強正則化效果 |
| 數據增強 | 多種增強組合 | 添加隨機旋轉、顏色抖動、隨機平移和隨機擦除 |

### 過擬合問題分析與解決方案

在本專案中，我們觀察到明顯的過擬合現象：
- 訓練準確率(85.19%)與測試準確率(58.04%)之間存在約27%的差距
- 測試損失在35個epoch後開始上升
- 訓練準確率持續上升而測試準確率趨於平緩

這些是典型的過擬合特徵，反映了模型在訓練集上"記憶"而非"學習"的問題。我們的解決方案針對性地解決了這一問題：增強正則化直接限制模型複雜度，增強數據增強擴大了有效訓練樣本，從最佳檢查點重新開始則避免了繼續在已經過擬合的模型上訓練。

## 最新更新 (2025年5月5日)

### 重大改進與錯誤修復

- **解決窗口分割和合併問題** - 修復了 `window_partition` 和 `window_reverse` 函數中的尺寸不匹配問題，支援任意圖像尺寸與窗口大小組合，新增了自動填充邏輯
- **修正張量連續性問題** - 將 `SwinTransformerBlock` 中的 `.view()` 替換為 `.reshape()`，解決了非連續內存錯誤
- **支援多種模型規格** - 新增 tiny、small、large 模型規格選擇，優化每種模型的參數配置和批次大小設置
- **添加預訓練權重支援** - 現在可使用指定的預訓練權重（如 `swinv2_large_patch4_window12_192_22k.pth`）進行微調
- **解決分散式訓練未使用參數問題** - 完全修改了 `forward` 方法中的參數處理邏輯，添加了虛擬損失機制，確保所有參數都參與計算，解決了 DDP 訓練中的梯度同步問題
- **修復 Checkpoint 重入問題** - 為 `torch.utils.checkpoint` 添加 `use_reentrant=False` 參數設置，解決了參數被多次標記為 "ready" 的問題
- **優化學習率調度器使用** - 將 `scheduler.step()` 從每個批次移至每個 epoch 後調用，並確保正確傳遞 epoch 參數
- **修正參數名稱不匹配問題** - 修復 `SwinTransformerV2` 初始化中的參數名稱錯誤（如 `img_size` 改為 `input_resolution`，`in_chans` 改為 `in_channels` 等）
- **解決測試功能參數不一致** - 修改 `test_epoch` 函數添加可選的 `logger` 參數，與實際調用保持一致
- **修正輸出維度不匹配問題** - 確保分類頭的輸出維度與類別數（101）一致

### 窗口操作和張量處理改進

- **自適應窗口填充** - 改進 `window_partition` 函數以處理輸入尺寸不是窗口大小整數倍的情況，自動進行填充處理
- **無縫窗口恢復** - 改進 `window_reverse` 函數，正確處理填充和裁剪操作，保持與 `window_partition` 的一致性
- **解決張量不連續問題** - 在關鍵張量操作中用 `reshape()` 替代 `view()` 以處理非連續內存張量
- **靈活處理多種窗口大小** - 支援多種窗口大小（7×7 和 12×12）與圖像尺寸（192×192 和 224×224）組合

### 對不同規格 Swin V2 的支援

| 模型規格 | 深度 (depths) | 嵌入維度 (embed_dim) | 頭數 (num_heads) | 批次大小 | 參數量 |
|---------|--------------|---------------------|-----------------|---------|--------|
| Tiny    | (2, 2, 6, 2) | 96                  | [3, 6, 12, 24]  | 64      | 最少   |
| Small   | (2, 2, 18, 2)| 96                  | [3, 6, 12, 24]  | 32      | 中等   |
| Base    | (2, 2, 18, 2)| 128                 | [4, 8, 16, 32]  | 32      | 較多   |
| Large   | (2, 2, 18, 2)| 192                 | [6, 12, 24, 48] | 16      | 最多   |

### 分散式訓練穩定性改進

- **添加 NCCL 調試環境變數** - 設置 `TORCH_DISTRIBUTED_DEBUG=DETAIL` 以獲取更詳細的分散式訓練錯誤信息
- **修補 checkpoint 功能** - 使用自定義包裝函數強制 `torch.utils.checkpoint.checkpoint` 設置 `use_reentrant=False`
- **解決靜態圖兼容性問題** - 添加對 `_set_static_graph` 方法的可用性檢查，確保在不支持的模型上不會出錯
- **處理特徵列表輸出** - 改進 `SwinTransformerV2Classifier.forward` 方法，正確處理backbone返回的特徵列表，從中提取最後一層特徵用於分類

### 預訓練權重使用

現在專案支援使用多種預訓練權重，包括:

- `swinv2_imagenet_pretrained.pth` - 基本 ImageNet 預訓練權重
- `swinv2_large_patch4_window12_192_22k.pth` - ImageNet-22K 預訓練的 Large 模型權重

預訓練權重的使用大幅提高了模型的準確率，特別是在從頭訓練準確率較低的情況下，可以從 <5% 提升到 80-90%。

## 模型參數設置 (2025年5月5日更新)

最新版本支援多種參數配置：

| 參數 | 數值範圍 | 說明 |
|------|---------|------|
| 圖像尺寸 | 192×192 或 224×224 | 可根據模型規格選擇適合的尺寸 |
| 窗口大小 | 7×7 或 12×12 | 根據模型規格和圖像尺寸調整 |
| 批次大小 | 16 (Large), 32 (Base/Small), 64 (Tiny) | 根據模型規格自動調整 |
| 訓練週期 | 50-100個epoch | 使用預訓練權重時可減少到50輪 |
| 學習率 | 2e-5 (微調) 或 1e-3 (從頭訓練) | 根據是否使用預訓練權重調整 |
| 權重衰減 | 0.05 (微調) 或 0.01 (從頭訓練) | 預訓練時可適當提高權重衰減 |
| 模型規格 | tiny, small, base, large | 可根據硬體資源和準確率需求選擇 |

## 安裝與環境設置

```bash
# 安裝所需的套件
pip install torch torchvision torchaudio timm tensorboard pillow scikit-learn pandas opencv-python matplotlib tqdm

# 解壓資料集（如果尚未解壓）
unzip food-101.zip
```

## 運行訓練

本專案使用 PyTorch 的分散式訓練功能，透過 `torchrun` 啟動：

### 單機多 GPU 訓練

```bash
# 使用多個 GPU 進行訓練
torchrun --nproc_per_node=N main.py
```
其中 N 為您想使用的 GPU 數量。

### 單 GPU 訓練

```bash
# 僅使用單個 GPU 進行訓練
torchrun --nproc_per_node=1 main.py
```

## 從頭訓練最佳實踐

本專案針對從頭訓練（training from scratch）優化了多個方面:

1. **特殊初始化策略** - 使用適合從頭訓練的權重初始化方法
2. **PreNorm 結構** - 在 Transformer 區塊中使用 PreNorm 代替 PostNorm 提高穩定性
3. **殘差縮放** - 訓練時使用 0.9 的縮放因子，避免梯度爆炸
4. **BatchNorm 整合** - 在關鍵位置引入 BatchNorm 層，增強從頭訓練穩定性
5. **較小的增強強度** - 降低數據增強強度，使模型更易收斂
6. **門控機制** - 在注意力機制中添加門控參數，改善注意力計算
7. **學習率優化** - 使用更大的初始學習率和更長的預熱期

## 多維度張量處理技巧

為解決 CNN 風格和 Transformer 風格張量格式不一致的問題，本專案使用以下技巧:

1. **自適應張量維度檢測** - 檢測輸入張量維度並動態調整處理方式
2. **維度轉換兼容層** - 在關鍵組件中添加張量維度轉換邏輯
3. **靈活的層標準化** - 根據張量維度動態選擇 LayerNorm 或 BatchNorm
4. **序列/空間特徵互換** - 在 `[B, C, H, W]` 和 `[B, L, C]` 格式間平滑轉換
5. **兼容性池化策略** - 對不同維度的張量使用不同的全局池化方法

## 記憶體優化策略 (2025年5月14日更新)

本專案採用多種技術減少記憶體使用量，適合在資源有限的環境下運行：

1. **降低圖像尺寸** - 從常見的 224×224 降至 192×192，減少特徵圖記憶體使用
2. **減小批次大小** - 從 32 降至 16，有效降低單次前向/後向傳播的記憶體需求
3. **降級模型規格** - 使用 "base" 變體替代 "large" 變體，大幅減少模型參數量
4. **梯度累積** - 實現梯度累積步驟 (GRAD_ACCUM_STEPS=2)，模擬較大批次同時降低記憶體使用
5. **混合精度訓練** - 使用 FP16 進行部分計算，降低記憶體佔用和計算時間
6. **Checkpoint 功能** - 反向傳播時重新計算部分結果而非全部保存在記憶體中
7. **優化數據加載器** - 降低預取因子並調整工作進程數，減少 CPU 記憶體壓力
8. **主動記憶體釋放** - 每 20 批次主動釋放未使用的 CUDA 記憶體
9. **確保 DataLoader 設置一致** - 維持測試階段與訓練相同的批次大小，避免評估時記憶體溢出
10. **縮放損失函數** - 在梯度累積實現中正確縮放損失值，確保數值穩定性

### 測試數據加載器優化

針對評估階段的記憶體問題，我們進行了以下改進：

- 確保測試數據加載器使用與訓練相同的批次大小 (BATCH_SIZE=16)
- 修正了錯誤的 DataLoader 批次大小修改方式
- 優化了代碼結構，修正語法錯誤，提高可讀性和穩定性
- 為不同型號 GPU 配置不同的批次大小和模型規格組合

這些優化使模型能夠在有限的 GPU 記憶體下穩定訓練，特別是對於較大的 Swin Transformer V2 模型，避免在訓練中期出現 CUDA 記憶體不足的問題。

## 高級資料增強策略

本專案採用了多項最新的資料增強技術，但為從頭訓練調整了參數：

1. **RandAugment** - 自動搜索和應用最佳增強策略組合
   - 設置強度(magnitude)為 3，操作數(num_ops)為 1
   - 顯著降低強度以提高從頭訓練穩定性

2. **Mixup 和 Cutmix** - 混合不同圖像及其標籤
   - Mixup Alpha: 0.4（降低）
   - Cutmix Alpha: 0.4（降低）
   - 混合概率: 0.3（降低）
   - 切換概率: 0.3（降低）

3. **RandomErasing** - 隨機遮擋圖像部分區域
   - 應用概率: 0.1（進一步降低）
   - 面積比例: 0.02-0.2（縮小範圍）
   - 長寬比: 0.3-3.3

## 學習率調度與優化器

- **優化器**: AdamW 優化器配合 0.01 權重衰減（降低衰減強度）
- **學習率策略**: CosineLRScheduler 實現余弦退火學習率
- **熱身期**: 20 個 epoch 的熱身期（延長），初始熱身學習率為 1e-6
- **最小學習率**: 1e-5（提高），確保末期仍有足夠的調整空間

## 穩定性優化與錯誤處理

為提高訓練過程的穩定性，我們實施了以下機制：

1. **自動處理 NaN/Inf 值** - 在檢測到 NaN 時跳過批次並降低學習率
2. **連續 NaN 處理** - 當連續出現 NaN 時自動降低學習率 50%
3. **梯度裁剪** - 最大 norm 降至 1.0（更小），防止梯度爆炸
4. **定期釋放記憶體** - 每 20 批次主動釋放未使用的 CUDA 記憶體（增加頻率）
5. **優化超時處理** - 增強 NCCL 通信超時處理機制
6. **維度兼容性檢查** - 增加張量維度動態檢查和處理邏輯

## 使用 Tensorboard 監控訓練

訓練過程中，程式會自動在 `runs/` 目錄中建立 Tensorboard 日誌。您可以使用以下命令啟動 Tensorboard 服務器：

```bash
tensorboard --logdir=runs
```

啟動後，在瀏覽器中訪問 http://localhost:6006 查看即時訓練數據。

## 常見問題排解

### 張量維度錯誤
若遇到 "too many values to unpack" 或 "not enough values to unpack" 錯誤：
- 問題通常出現在張量維度不匹配（3D vs 4D）
- 檢查模型是否正確處理 [B, L, C] 和 [B, C, H, W] 格式轉換
- 最新版本已自動處理此類問題

### 訓練不穩定或 NaN 值
- 使用較小的學習率（如 5e-5）開始訓練
- 使用更小的批次大小（16 或 8）
- 禁用或減弱 Mixup/Cutmix 增強
- 檢查模型是否使用了 PreNorm 架構
- 確保啟用了梯度裁剪（max_norm=1.0）

### 分散式訓練問題
- 檢查 NCCL 超時設置（已預設增加到 3600 秒）
- 確認所有 GPU 可用且工作正常
- 使用 '--find_unused_parameters=True' 參數
- 在啟動訓練前檢查網絡連接

## 檔案結構說明

- `main.py` - 主程式，包含訓練和評估邏輯
- `swin_transformer_v2_classifier.py` - Swin V2 分類器定義
- `swin_transformer_v2/` - Swin V2 模型的核心實現
  - `model.py` - 模型架構定義
  - `model_parts.py` - 各個組件的實現（已優化支持多維度張量）
- `custom_model_parts.py` - 自定義模型組件
- `tools/` - 輔助工具腳本

## 版本記錄

### v1.0.0 (2025年4月)
- 初始版本發布
- 基本的 Swin Transformer V2 實現
- 支持分散式訓練和混合精度

### v1.1.0 (2025年5月)
- 修復多個張量維度兼容性問題
- 增強從頭訓練的穩定性和效率
- 添加門控注意力機制
- 改進維度轉換邏輯
- 整合 LayerNorm 和 BatchNorm 選擇
- 修復代碼中的語法錯誤
- 更新訓練參數配置

### v1.1.1 (2025年5月)
- 加強測試模型腳本的穩定性與兼容性
- 改進CAM生成功能，支援非分散式訓練模型
- 增加模型載入時的靈活性，支援忽略不匹配的參數
- 添加詳細的錯誤處理和診斷信息
- 優化CAM視覺化處理流程，提高生成品質

### v1.3.0 (2025年5月12日)
- 解決過度正則化問題，優化模型學習能力
- 增大窗口大小(7→12)，捕捉更大範圍特徵
- 降低正則化強度(dropout_path: 0.3→0.2)
- 減輕數據增強和混合策略強度
- 提高學習率，加速模型學習
- 增加訓練輪數(50→80)，給予充分學習時間
- 添加 NCCL 調試環境變數，優化分散式訓練錯誤診斷
- 改進錯誤處理機制，提高訓練穩定性

### v1.3.1 (2025年5月14日)
- 修復 DataLoader 批次大小問題，確保評估階段使用正確的批次大小設定
- 優化程式碼結構，修正語法錯誤和不當的註釋放置
- 改進測試數據加載器配置，與訓練數據加載器保持一致的批次大小
- 增強記憶體管理，確保評估階段不會出現內存不足問題

### v1.3.2 (2025年5月19日)
- 針對 `swinv1_to_swinv2.py` 腳本中的過度擬合問題進行了優化：
    - 增強數據擴增：引入 `RandomResizedCrop`、`RandomRotation` 和 `ColorJitter`。
    - 模型正則化：為 SwinV1 和 SwinV2 模型添加 `drop_rate=0.2` 和 `drop_path_rate=0.2`。
    - 優化器調整：在 `AdamW` 優化器中明確設定 `weight_decay=0.01`。
- 確保 TensorBoard 相關套件已安裝。

### v1.2.1 (2025年5月5日)
- 修復窗口分割和合併問題，支援任意圖像尺寸與窗口大小組合
- 修正張量連續性問題，解決非連續內存錯誤
- 新增 tiny、small、large 模型規格選擇
- 添加預訓練權重支援，提高模型準確率

## 未來改進計劃

1. **特徵蒸餾** - 整合知識蒸餾技術提高小型模型效果
2. **量化優化** - 支持 INT8 量化以進一步降低推理成本
3. **DeepSpeed 整合** - 加入 DeepSpeed 支持，提供更多分散式訓練選項
4. **自動化參數調優** - 加入 Optuna 等自動搜索最佳參數的能力
5. **集成學習支持** - 實現模型集成以進一步提高準確率
6. **視覺解釋增強** - 擴展可視化工具，更好理解模型決策過程

## 圖片可視化

模型包含 Class Activation Map (CAM) 可視化功能，可用於理解模型如何識別不同食物類別：

```python
# 生成 CAM 圖
image_tensor = transform(image).unsqueeze(0)
cam = generate_cam_swin_v2(model, image_tensor)
overlay = visualize_cam(image_tensor[0], cam)
plt.imshow(overlay)
plt.show()
```

## 模型測試與評估

本專案提供了專用的測試腳本`test_model.py`，用於評估已訓練好的模型。這個腳本可以載入預訓練模型，對Food-101測試集進行評估，並提供多種視覺化功能。

### 基本用法

```bash
# 基本測試：僅評估模型準確率
python test_model.py

# 生成可視化結果：包括每個類別的準確率、混淆矩陣和CAM可視化
python test_model.py --visualize

# 自訂可視化樣本數量
python test_model.py --visualize --num_visualize 10
```

### 參數說明

| 參數 | 說明 |
|------|------|
| `--weights` | 模型權重檔案路徑，預設為 'outputs/swinv2_food101_best.pth' |
| `--image_size` | 輸入圖像大小，預設為224 |
| `--window_size` | 窗口大小，預設為7 |
| `--batch_size` | 批次大小，預設為32 |
| `--data_root` | 資料集根目錄，預設為'food-101' |
| `--visualize` | 是否生成CAM可視化圖像 |
| `--num_visualize` | 要可視化的樣本數量，預設為5 |

### 主要功能

1. **模型評估**：計算模型在整個測試集上的準確率和損失值
2. **類別分析**：計算每個類別的準確率，幫助分析模型在不同食物類別上的表現
3. **混淆矩陣**：生成前10個常見類別的混淆矩陣，便於識別模型的優勢和弱點
4. **CAM視覺化**：生成類別激活圖(Class Activation Map)，有助於理解模型如何識別不同的食物

測試腳本會自動處理分散式訓練模型(DDP)的權重載入，確保模型能被正確評估，無論其是如何訓練的。

### 視覺化輸出

測試後的視覺化結果將被保存在以下位置：
- `confusion_matrix.png`：混淆矩陣圖像
- `cam_visualization/`：包含所有生成的CAM視覺化圖像

CAM視覺化包含三部分：原始圖像、熱力圖和疊加圖像，便於理解模型關注圖像的哪些區域。
