# Swin Transformer V2 於 Food-101 資料集分類

這個專案使用 Swin Transformer V2 模型對 Food-101 食物圖像資料集進行分類訓練。

## 專案簡介

本專案使用最新的 Swin Transformer V2 模型架構，針對 Food-101 資料集（包含 101 類食物圖像）進行分類任務訓練。專案特色：

- 使用 Swin Transformer V2 模型進行深度學習
- 採用分散式訓練（DistributedDataParallel）提高訓練效率
- 應用混合精度訓練（AMP）加速訓練過程
- 整合進階資料增強技術如 RandAugment、Mixup 和 Cutmix
- 採用 Stochastic Depth 提高深層網路泛化能力
- 使用 Tensorboard 視覺化訓練過程和關鍵指標
- 完整的日誌記錄系統
- 自適應錯誤處理機制以提高訓練穩定性

## 最新更新 (2025年5月5日)

### 重大改進與錯誤修復

- **解決窗口分割和合併問題** - 修復了 `window_partition` 和 `window_reverse` 函數中的尺寸不匹配問題，支援任意圖像尺寸與窗口大小組合，新增了自動填充邏輯
- **修正張量連續性問題** - 將 `SwinTransformerBlock` 中的 `.view()` 替換為 `.reshape()`，解決了非連續內存錯誤
- **支援多種模型規格** - 新增 tiny、small、large 模型規格選擇，優化每種模型的參數配置和批次大小設置
- **添加預訓練權重支援** - 現在可使用指定的預訓練權重（如 `swinv2_large_patch4_window12_192_22k.pth`）進行微調
- **解決分散式訓練未使用參數問題** - 完全修改了 `forward` 方法中的參數處理邏輯，添加了虛擬損失機制，確保所有參數都參與計算，解決了 DDP 訓練中的梯度同步問題
- **修復 Checkpoint 重入問題** - 為 `torch.utils.checkpoint` 添加 `use_reentrant=False` 參數設置，解決了參數被多次標記為 "ready" 的問題
- **優化學習率調度器使用** - 將 `scheduler.step()` 從每個批次移至每個 epoch 後調用，並確保正確傳遞 epoch 參數
- **修正參數名稱不匹配問題** - 修復 `SwinTransformerV2` 初始化中的參數名稱錯誤（如 `img_size` 改為 `input_resolution`，`in_chans` 改為 `in_channels` 等）
- **解決測試功能參數不一致** - 修改 `test_epoch` 函數添加可選的 `logger` 參數，與實際調用保持一致
- **修正輸出維度不匹配問題** - 確保分類頭的輸出維度與類別數（101）一致

### 窗口操作和張量處理改進

- **自適應窗口填充** - 改進 `window_partition` 函數以處理輸入尺寸不是窗口大小整數倍的情況，自動進行填充處理
- **無縫窗口恢復** - 改進 `window_reverse` 函數，正確處理填充和裁剪操作，保持與 `window_partition` 的一致性
- **解決張量不連續問題** - 在關鍵張量操作中用 `reshape()` 替代 `view()` 以處理非連續內存張量
- **靈活處理多種窗口大小** - 支援多種窗口大小（7×7 和 12×12）與圖像尺寸（192×192 和 224×224）組合

### 對不同規格 Swin V2 的支援

| 模型規格 | 深度 (depths) | 嵌入維度 (embed_dim) | 頭數 (num_heads) | 批次大小 | 參數量 |
|---------|--------------|---------------------|-----------------|---------|--------|
| Tiny    | (2, 2, 6, 2) | 96                  | [3, 6, 12, 24]  | 64      | 最少   |
| Small   | (2, 2, 18, 2)| 96                  | [3, 6, 12, 24]  | 32      | 中等   |
| Base    | (2, 2, 18, 2)| 128                 | [4, 8, 16, 32]  | 32      | 較多   |
| Large   | (2, 2, 18, 2)| 192                 | [6, 12, 24, 48] | 16      | 最多   |

### 分散式訓練穩定性改進

- **添加 NCCL 調試環境變數** - 設置 `TORCH_DISTRIBUTED_DEBUG=DETAIL` 以獲取更詳細的分散式訓練錯誤信息
- **修補 checkpoint 功能** - 使用自定義包裝函數強制 `torch.utils.checkpoint.checkpoint` 設置 `use_reentrant=False`
- **解決靜態圖兼容性問題** - 添加對 `_set_static_graph` 方法的可用性檢查，確保在不支持的模型上不會出錯
- **處理特徵列表輸出** - 改進 `SwinTransformerV2Classifier.forward` 方法，正確處理backbone返回的特徵列表，從中提取最後一層特徵用於分類

### 預訓練權重使用

現在專案支援使用多種預訓練權重，包括:

- `swinv2_imagenet_pretrained.pth` - 基本 ImageNet 預訓練權重
- `swinv2_large_patch4_window12_192_22k.pth` - ImageNet-22K 預訓練的 Large 模型權重

預訓練權重的使用大幅提高了模型的準確率，特別是在從頭訓練準確率較低的情況下，可以從 <5% 提升到 80-90%。

## 模型參數設置 (2025年5月5日更新)

最新版本支援多種參數配置：

| 參數 | 數值範圍 | 說明 |
|------|---------|------|
| 圖像尺寸 | 192×192 或 224×224 | 可根據模型規格選擇適合的尺寸 |
| 窗口大小 | 7×7 或 12×12 | 根據模型規格和圖像尺寸調整 |
| 批次大小 | 16 (Large), 32 (Base/Small), 64 (Tiny) | 根據模型規格自動調整 |
| 訓練週期 | 50-100個epoch | 使用預訓練權重時可減少到50輪 |
| 學習率 | 2e-5 (微調) 或 1e-3 (從頭訓練) | 根據是否使用預訓練權重調整 |
| 權重衰減 | 0.05 (微調) 或 0.01 (從頭訓練) | 預訓練時可適當提高權重衰減 |
| 模型規格 | tiny, small, base, large | 可根據硬體資源和準確率需求選擇 |

## 安裝與環境設置

```bash
# 安裝所需的套件
pip install torch torchvision torchaudio timm tensorboard pillow scikit-learn pandas opencv-python matplotlib tqdm

# 解壓資料集（如果尚未解壓）
unzip food-101.zip
```

## 運行訓練

本專案使用 PyTorch 的分散式訓練功能，透過 `torchrun` 啟動：

### 單機多 GPU 訓練

```bash
# 使用多個 GPU 進行訓練
torchrun --nproc_per_node=N main.py
```
其中 N 為您想使用的 GPU 數量。

### 單 GPU 訓練

```bash
# 僅使用單個 GPU 進行訓練
torchrun --nproc_per_node=1 main.py
```

## 從頭訓練最佳實踐

本專案針對從頭訓練（training from scratch）優化了多個方面:

1. **特殊初始化策略** - 使用適合從頭訓練的權重初始化方法
2. **PreNorm 結構** - 在 Transformer 區塊中使用 PreNorm 代替 PostNorm 提高穩定性
3. **殘差縮放** - 訓練時使用 0.9 的縮放因子，避免梯度爆炸
4. **BatchNorm 整合** - 在關鍵位置引入 BatchNorm 層，增強從頭訓練穩定性
5. **較小的增強強度** - 降低數據增強強度，使模型更易收斂
6. **門控機制** - 在注意力機制中添加門控參數，改善注意力計算
7. **學習率優化** - 使用更大的初始學習率和更長的預熱期

## 多維度張量處理技巧

為解決 CNN 風格和 Transformer 風格張量格式不一致的問題，本專案使用以下技巧:

1. **自適應張量維度檢測** - 檢測輸入張量維度並動態調整處理方式
2. **維度轉換兼容層** - 在關鍵組件中添加張量維度轉換邏輯
3. **靈活的層標準化** - 根據張量維度動態選擇 LayerNorm 或 BatchNorm
4. **序列/空間特徵互換** - 在 `[B, C, H, W]` 和 `[B, L, C]` 格式間平滑轉換
5. **兼容性池化策略** - 對不同維度的張量使用不同的全局池化方法

## 記憶體優化策略

本專案採用多種技術減少記憶體使用量，適合在資源有限的環境下運行：

1. **降低圖像尺寸** - 從常見的 224×224 降至 192×192（可選設定）
2. **減小批次大小** - 設置為 32，適應大多數 GPU
3. **梯度累積** - 使用梯度累積模擬更大批次
4. **混合精度訓練** - 使用 FP16 進行部分計算
5. **Checkpoint 功能** - 在反向傳播時重新計算某些結果而非保存在記憶體中
6. **優化數據加載器** - 降低預取因子並調整工作進程數
7. **主動記憶體釋放** - 定期釋放未使用的 CUDA 記憶體

## 高級資料增強策略

本專案採用了多項最新的資料增強技術，但為從頭訓練調整了參數：

1. **RandAugment** - 自動搜索和應用最佳增強策略組合
   - 設置強度(magnitude)為 3，操作數(num_ops)為 1
   - 顯著降低強度以提高從頭訓練穩定性

2. **Mixup 和 Cutmix** - 混合不同圖像及其標籤
   - Mixup Alpha: 0.4（降低）
   - Cutmix Alpha: 0.4（降低）
   - 混合概率: 0.3（降低）
   - 切換概率: 0.3（降低）

3. **RandomErasing** - 隨機遮擋圖像部分區域
   - 應用概率: 0.1（進一步降低）
   - 面積比例: 0.02-0.2（縮小範圍）
   - 長寬比: 0.3-3.3

## 學習率調度與優化器

- **優化器**: AdamW 優化器配合 0.01 權重衰減（降低衰減強度）
- **學習率策略**: CosineLRScheduler 實現余弦退火學習率
- **熱身期**: 20 個 epoch 的熱身期（延長），初始熱身學習率為 1e-6
- **最小學習率**: 1e-5（提高），確保末期仍有足夠的調整空間

## 穩定性優化與錯誤處理

為提高訓練過程的穩定性，我們實施了以下機制：

1. **自動處理 NaN/Inf 值** - 在檢測到 NaN 時跳過批次並降低學習率
2. **連續 NaN 處理** - 當連續出現 NaN 時自動降低學習率 50%
3. **梯度裁剪** - 最大 norm 降至 1.0（更小），防止梯度爆炸
4. **定期釋放記憶體** - 每 20 批次主動釋放未使用的 CUDA 記憶體（增加頻率）
5. **優化超時處理** - 增強 NCCL 通信超時處理機制
6. **維度兼容性檢查** - 增加張量維度動態檢查和處理邏輯

## 使用 Tensorboard 監控訓練

訓練過程中，程式會自動在 `runs/` 目錄中建立 Tensorboard 日誌。您可以使用以下命令啟動 Tensorboard 服務器：

```bash
tensorboard --logdir=runs
```

啟動後，在瀏覽器中訪問 http://localhost:6006 查看即時訓練數據。

## 常見問題排解

### 張量維度錯誤
若遇到 "too many values to unpack" 或 "not enough values to unpack" 錯誤：
- 問題通常出現在張量維度不匹配（3D vs 4D）
- 檢查模型是否正確處理 [B, L, C] 和 [B, C, H, W] 格式轉換
- 最新版本已自動處理此類問題

### 訓練不穩定或 NaN 值
- 使用較小的學習率（如 5e-5）開始訓練
- 使用更小的批次大小（16 或 8）
- 禁用或減弱 Mixup/Cutmix 增強
- 檢查模型是否使用了 PreNorm 架構
- 確保啟用了梯度裁剪（max_norm=1.0）

### 分散式訓練問題
- 檢查 NCCL 超時設置（已預設增加到 3600 秒）
- 確認所有 GPU 可用且工作正常
- 使用 '--find_unused_parameters=True' 參數
- 在啟動訓練前檢查網絡連接

## 檔案結構說明

- `main.py` - 主程式，包含訓練和評估邏輯
- `swin_transformer_v2_classifier.py` - Swin V2 分類器定義
- `swin_transformer_v2/` - Swin V2 模型的核心實現
  - `model.py` - 模型架構定義
  - `model_parts.py` - 各個組件的實現（已優化支持多維度張量）
- `custom_model_parts.py` - 自定義模型組件
- `tools/` - 輔助工具腳本

## 版本記錄

### v1.0.0 (2025年4月)
- 初始版本發布
- 基本的 Swin Transformer V2 實現
- 支持分散式訓練和混合精度

### v1.1.0 (2025年5月)
- 修復多個張量維度兼容性問題
- 增強從頭訓練的穩定性和效率
- 添加門控注意力機制
- 改進維度轉換邏輯
- 整合 LayerNorm 和 BatchNorm 選擇
- 修復代碼中的語法錯誤
- 更新訓練參數配置

### v1.1.1 (2025年5月)
- 加強測試模型腳本的穩定性與兼容性
- 改進CAM生成功能，支援非分散式訓練模型
- 增加模型載入時的靈活性，支援忽略不匹配的參數
- 添加詳細的錯誤處理和診斷信息
- 優化CAM視覺化處理流程，提高生成品質

### v1.2.0 (2025年5月4日)
- 全面解決分散式訓練中的未使用參數問題
- 修復 checkpoint 功能的重入問題（use_reentrant=False）
- 優化學習率調度器的使用方式，從每批次改為每個 epoch
- 修正 SwinTransformerV2 初始化參數命名不一致問題
- 引入虛擬梯度流動機制，確保所有參數參與計算
- 解決維度不匹配和特徵列表處理問題
- 添加 NCCL 調試環境變數，優化分散式訓練錯誤診斷
- 改進錯誤處理機制，提高訓練穩定性

### v1.2.1 (2025年5月5日)
- 修復窗口分割和合併問題，支援任意圖像尺寸與窗口大小組合
- 修正張量連續性問題，解決非連續內存錯誤
- 新增 tiny、small、large 模型規格選擇
- 添加預訓練權重支援，提高模型準確率

## 未來改進計劃

1. **特徵蒸餾** - 整合知識蒸餾技術提高小型模型效果
2. **量化優化** - 支持 INT8 量化以進一步降低推理成本
3. **DeepSpeed 整合** - 加入 DeepSpeed 支持，提供更多分散式訓練選項
4. **自動化參數調優** - 加入 Optuna 等自動搜索最佳參數的能力
5. **集成學習支持** - 實現模型集成以進一步提高準確率
6. **視覺解釋增強** - 擴展可視化工具，更好理解模型決策過程

## 圖片可視化

模型包含 Class Activation Map (CAM) 可視化功能，可用於理解模型如何識別不同食物類別：

```python
# 生成 CAM 圖
image_tensor = transform(image).unsqueeze(0)
cam = generate_cam_swin_v2(model, image_tensor)
overlay = visualize_cam(image_tensor[0], cam)
plt.imshow(overlay)
plt.show()
```

## 模型測試與評估

本專案提供了專用的測試腳本`test_model.py`，用於評估已訓練好的模型。這個腳本可以載入預訓練模型，對Food-101測試集進行評估，並提供多種視覺化功能。

### 基本用法

```bash
# 基本測試：僅評估模型準確率
python test_model.py

# 生成可視化結果：包括每個類別的準確率、混淆矩陣和CAM可視化
python test_model.py --visualize

# 自訂可視化樣本數量
python test_model.py --visualize --num_visualize 10
```

### 參數說明

| 參數 | 說明 |
|------|------|
| `--weights` | 模型權重檔案路徑，預設為 'outputs/swinv2_food101_best.pth' |
| `--image_size` | 輸入圖像大小，預設為224 |
| `--window_size` | 窗口大小，預設為7 |
| `--batch_size` | 批次大小，預設為32 |
| `--data_root` | 資料集根目錄，預設為'food-101' |
| `--visualize` | 是否生成CAM可視化圖像 |
| `--num_visualize` | 要可視化的樣本數量，預設為5 |

### 主要功能

1. **模型評估**：計算模型在整個測試集上的準確率和損失值
2. **類別分析**：計算每個類別的準確率，幫助分析模型在不同食物類別上的表現
3. **混淆矩陣**：生成前10個常見類別的混淆矩陣，便於識別模型的優勢和弱點
4. **CAM視覺化**：生成類別激活圖(Class Activation Map)，有助於理解模型如何識別不同的食物

測試腳本會自動處理分散式訓練模型(DDP)的權重載入，確保模型能被正確評估，無論其是如何訓練的。

### 視覺化輸出

測試後的視覺化結果將被保存在以下位置：
- `confusion_matrix.png`：混淆矩陣圖像
- `cam_visualization/`：包含所有生成的CAM視覺化圖像

CAM視覺化包含三部分：原始圖像、熱力圖和疊加圖像，便於理解模型關注圖像的哪些區域。
