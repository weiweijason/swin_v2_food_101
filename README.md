# Swin Transformer V2 於 Food-101 資料集分類

這個專案使用 Swin Transformer V2 模型對 Food-101 食物圖像資料集進行分類訓練。

## 專案簡介

本專案使用最新的 Swin Transformer V2 模型架構，針對 Food-101 資料集（包含 101 類食物圖像）進行分類任務訓練。專案特色：

- 使用 Swin Transformer V2 模型進行深度學習
- 採用分散式訓練（DistributedDataParallel）提高訓練效率
- 應用混合精度訓練（AMP）加速訓練過程
- 整合進階資料增強技術如 RandAugment、Mixup 和 Cutmix
- 採用 Stochastic Depth 提高深層網路泛化能力
- 使用 Tensorboard 視覺化訓練過程和關鍵指標
- 完整的日誌記錄系統
- 自適應錯誤處理機制以提高訓練穩定性

## 最新更新 (2025年5月)

### 重大錯誤修復和穩定性改進

- **修復張量維度不匹配問題** - 修正了 `SwinTransformerBlock.forward` 方法中的張量維度處理，使其能夠同時接受 3D 張量 `[B, L, C]` 和 4D 張量 `[B, C, H, W]` 格式
- **增強下採樣兼容性** - 改進了 `PatchMerging.forward` 方法，支持不同維度的輸入張量，確保在模型不同層級間張量維度的統一性
- **修復特徵提取穩定性** - 更新了 `SwinTransformerV2Classifier.forward_features` 方法，加入了自適應維度處理邏輯
- **添加關鍵缺失組件** - 補充了缺失的 `dummy_param` 和 `aux_head` 等關鍵組件，提高模型訓練穩定性
- **修復代碼語法錯誤** - 修正了 `main.py` 中的中文變量混入問題，將 `gradient_accumulation_steps或is_last_batch` 改為正確的邏輯表達式

### 從頭訓練增強功能

- **添加殘差縮放** - 在訓練階段使用殘差縮放因子(0.9)，增強梯度傳遞效率
- **動態標準化支持** - 增加動態創建適用於 3D 張量的標準化層，確保維度轉換的兼容性
- **門控注意力機制** - 在 WindowAttention 中添加門控機制，提高從頭訓練的效果與穩定性
- **強化初始化策略** - 對 meta network 權重使用截斷正態分布進行初始化，提高訓練初期穩定性
- **優化特徵池化** - 根據張量維度自動選擇合適的池化方式，確保特徵提取的一致性

## 模型參數設置 (2025年5月更新)

最新版本的訓練參數：

| 參數 | 數值 | 說明 |
|------|------|------|
| 圖像尺寸 | 224×224 | 標準輸入尺寸，提高模型準確度 |
| 窗口大小 | 7×7 | 標準窗口大小，與圖像尺寸兼容 |
| 批次大小 | 32 | 較小的批次大小以適應記憶體限制 |
| 訓練週期 | 200個epoch | 大幅增加訓練輪數，適應從頭訓練需求 |
| 學習率 | 1e-3 | 提高初始學習率，適合從頭訓練 |
| 權重衰減 | 0.01 | 降低權重衰減，避免阻礙從頭訓練收斂 |
| 隨機深度率 | 0.2 | 增加 Stochastic Depth 比率提高泛化能力 |
| 梯度累積步數 | 2 | 使用較小的梯度累積步數提高訓練效率 |
| 預熱週期 | 20個epoch | 更長的預熱期，有助於從頭訓練穩定性 |

## 安裝與環境設置

```bash
# 安裝所需的套件
pip install torch torchvision torchaudio timm tensorboard pillow scikit-learn pandas opencv-python matplotlib tqdm

# 解壓資料集（如果尚未解壓）
unzip food-101.zip
```

## 運行訓練

本專案使用 PyTorch 的分散式訓練功能，透過 `torchrun` 啟動：

### 單機多 GPU 訓練

```bash
# 使用多個 GPU 進行訓練
torchrun --nproc_per_node=N main.py
```
其中 N 為您想使用的 GPU 數量。

### 單 GPU 訓練

```bash
# 僅使用單個 GPU 進行訓練
torchrun --nproc_per_node=1 main.py
```

## 從頭訓練最佳實踐

本專案針對從頭訓練（training from scratch）優化了多個方面:

1. **特殊初始化策略** - 使用適合從頭訓練的權重初始化方法
2. **PreNorm 結構** - 在 Transformer 區塊中使用 PreNorm 代替 PostNorm 提高穩定性
3. **殘差縮放** - 訓練時使用 0.9 的縮放因子，避免梯度爆炸
4. **BatchNorm 整合** - 在關鍵位置引入 BatchNorm 層，增強從頭訓練穩定性
5. **較小的增強強度** - 降低數據增強強度，使模型更易收斂
6. **門控機制** - 在注意力機制中添加門控參數，改善注意力計算
7. **學習率優化** - 使用更大的初始學習率和更長的預熱期

## 多維度張量處理技巧

為解決 CNN 風格和 Transformer 風格張量格式不一致的問題，本專案使用以下技巧:

1. **自適應張量維度檢測** - 檢測輸入張量維度並動態調整處理方式
2. **維度轉換兼容層** - 在關鍵組件中添加張量維度轉換邏輯
3. **靈活的層標準化** - 根據張量維度動態選擇 LayerNorm 或 BatchNorm
4. **序列/空間特徵互換** - 在 `[B, C, H, W]` 和 `[B, L, C]` 格式間平滑轉換
5. **兼容性池化策略** - 對不同維度的張量使用不同的全局池化方法

## 記憶體優化策略

本專案採用多種技術減少記憶體使用量，適合在資源有限的環境下運行：

1. **降低圖像尺寸** - 從常見的 224×224 降至 192×192（可選設定）
2. **減小批次大小** - 設置為 32，適應大多數 GPU
3. **梯度累積** - 使用梯度累積模擬更大批次
4. **混合精度訓練** - 使用 FP16 進行部分計算
5. **Checkpoint 功能** - 在反向傳播時重新計算某些結果而非保存在記憶體中
6. **優化數據加載器** - 降低預取因子並調整工作進程數
7. **主動記憶體釋放** - 定期釋放未使用的 CUDA 記憶體

## 高級資料增強策略

本專案採用了多項最新的資料增強技術，但為從頭訓練調整了參數：

1. **RandAugment** - 自動搜索和應用最佳增強策略組合
   - 設置強度(magnitude)為 3，操作數(num_ops)為 1
   - 顯著降低強度以提高從頭訓練穩定性

2. **Mixup 和 Cutmix** - 混合不同圖像及其標籤
   - Mixup Alpha: 0.4（降低）
   - Cutmix Alpha: 0.4（降低）
   - 混合概率: 0.3（降低）
   - 切換概率: 0.3（降低）

3. **RandomErasing** - 隨機遮擋圖像部分區域
   - 應用概率: 0.1（進一步降低）
   - 面積比例: 0.02-0.2（縮小範圍）
   - 長寬比: 0.3-3.3

## 學習率調度與優化器

- **優化器**: AdamW 優化器配合 0.01 權重衰減（降低衰減強度）
- **學習率策略**: CosineLRScheduler 實現余弦退火學習率
- **熱身期**: 20 個 epoch 的熱身期（延長），初始熱身學習率為 1e-6
- **最小學習率**: 1e-5（提高），確保末期仍有足夠的調整空間

## 穩定性優化與錯誤處理

為提高訓練過程的穩定性，我們實施了以下機制：

1. **自動處理 NaN/Inf 值** - 在檢測到 NaN 時跳過批次並降低學習率
2. **連續 NaN 處理** - 當連續出現 NaN 時自動降低學習率 50%
3. **梯度裁剪** - 最大 norm 降至 1.0（更小），防止梯度爆炸
4. **定期釋放記憶體** - 每 20 批次主動釋放未使用的 CUDA 記憶體（增加頻率）
5. **優化超時處理** - 增強 NCCL 通信超時處理機制
6. **維度兼容性檢查** - 增加張量維度動態檢查和處理邏輯

## 使用 Tensorboard 監控訓練

訓練過程中，程式會自動在 `runs/` 目錄中建立 Tensorboard 日誌。您可以使用以下命令啟動 Tensorboard 服務器：

```bash
tensorboard --logdir=runs
```

啟動後，在瀏覽器中訪問 http://localhost:6006 查看即時訓練數據。

## 常見問題排解

### 張量維度錯誤
若遇到 "too many values to unpack" 或 "not enough values to unpack" 錯誤：
- 問題通常出現在張量維度不匹配（3D vs 4D）
- 檢查模型是否正確處理 [B, L, C] 和 [B, C, H, W] 格式轉換
- 最新版本已自動處理此類問題

### 訓練不穩定或 NaN 值
- 使用較小的學習率（如 5e-5）開始訓練
- 使用更小的批次大小（16 或 8）
- 禁用或減弱 Mixup/Cutmix 增強
- 檢查模型是否使用了 PreNorm 架構
- 確保啟用了梯度裁剪（max_norm=1.0）

### 分散式訓練問題
- 檢查 NCCL 超時設置（已預設增加到 3600 秒）
- 確認所有 GPU 可用且工作正常
- 使用 '--find_unused_parameters=True' 參數
- 在啟動訓練前檢查網絡連接

## 檔案結構說明

- `main.py` - 主程式，包含訓練和評估邏輯
- `swin_transformer_v2_classifier.py` - Swin V2 分類器定義
- `swin_transformer_v2/` - Swin V2 模型的核心實現
  - `model.py` - 模型架構定義
  - `model_parts.py` - 各個組件的實現（已優化支持多維度張量）
- `custom_model_parts.py` - 自定義模型組件
- `tools/` - 輔助工具腳本

## 版本記錄

### v1.0.0 (2025年4月)
- 初始版本發布
- 基本的 Swin Transformer V2 實現
- 支持分散式訓練和混合精度

### v1.1.0 (2025年5月)
- 修復多個張量維度兼容性問題
- 增強從頭訓練的穩定性和效率
- 添加門控注意力機制
- 改進維度轉換邏輯
- 整合 LayerNorm 和 BatchNorm 選擇
- 修復代碼中的語法錯誤
- 更新訓練參數配置

## 未來改進計劃

1. **特徵蒸餾** - 整合知識蒸餾技術提高小型模型效果
2. **量化優化** - 支持 INT8 量化以進一步降低推理成本
3. **DeepSpeed 整合** - 加入 DeepSpeed 支持，提供更多分散式訓練選項
4. **自動化參數調優** - 加入 Optuna 等自動搜索最佳參數的能力
5. **集成學習支持** - 實現模型集成以進一步提高準確率
6. **視覺解釋增強** - 擴展可視化工具，更好理解模型決策過程

## 圖片可視化

模型包含 Class Activation Map (CAM) 可視化功能，可用於理解模型如何識別不同食物類別：

```python
# 生成 CAM 圖
image_tensor = transform(image).unsqueeze(0)
cam = generate_cam_swin_v2(model, image_tensor)
overlay = visualize_cam(image_tensor[0], cam)
plt.imshow(overlay)
plt.show()
```

## 模型測試與評估

本專案提供了專用的測試腳本`test_model.py`，用於評估已訓練好的模型。這個腳本可以載入預訓練模型，對Food-101測試集進行評估，並提供多種視覺化功能。

### 基本用法

```bash
# 基本測試：僅評估模型準確率
python test_model.py

# 生成可視化結果：包括每個類別的準確率、混淆矩陣和CAM可視化
python test_model.py --visualize

# 自訂可視化樣本數量
python test_model.py --visualize --num_visualize 10
```

### 參數說明

| 參數 | 說明 |
|------|------|
| `--weights` | 模型權重檔案路徑，預設為 'outputs/swinv2_food101_best.pth' |
| `--image_size` | 輸入圖像大小，預設為224 |
| `--window_size` | 窗口大小，預設為7 |
| `--batch_size` | 批次大小，預設為32 |
| `--data_root` | 資料集根目錄，預設為'food-101' |
| `--visualize` | 是否生成CAM可視化圖像 |
| `--num_visualize` | 要可視化的樣本數量，預設為5 |

### 主要功能

1. **模型評估**：計算模型在整個測試集上的準確率和損失值
2. **類別分析**：計算每個類別的準確率，幫助分析模型在不同食物類別上的表現
3. **混淆矩陣**：生成前10個常見類別的混淆矩陣，便於識別模型的優勢和弱點
4. **CAM視覺化**：生成類別激活圖(Class Activation Map)，有助於理解模型如何識別不同的食物

測試腳本會自動處理分散式訓練模型(DDP)的權重載入，確保模型能被正確評估，無論其是如何訓練的。

### 視覺化輸出

測試後的視覺化結果將被保存在以下位置：
- `confusion_matrix.png`：混淆矩陣圖像
- `cam_visualization/`：包含所有生成的CAM視覺化圖像

CAM視覺化包含三部分：原始圖像、熱力圖和疊加圖像，便於理解模型關注圖像的哪些區域。
