增強數據擴增策略：

為訓練集添加了隨機裁剪、水平翻轉、色彩抖動等
優化了測試集的數據處理流程，使用了適合評估的中心裁剪
優化學習率與訓練策略：

實現了分層學習率，讓骨幹網路使用較低的學習率 (1e-5)，分類頭使用較高學習率 (5e-5)
使用了更先進的 CosineLRScheduler，加入了 5 個 epoch 的熱身期
增加了權重衰減至 0.05 提供更好的正則化效果
添加混合精度訓練：

使用 PyTorch 的 autocast 和 GradScaler 實現了混合精度訓練
這將加速訓練過程 (約 1.3-2 倍)，同時降低 GPU 記憶體占用
增加標籤平滑和正則化：

設置了 0.1 的標籤平滑度
加入了梯度裁剪 (max_norm=5.0) 以提高訓練穩定性
增加 batch size：

將批次大小從 32 提高到 64，提高訓練效率和潛在準確率
